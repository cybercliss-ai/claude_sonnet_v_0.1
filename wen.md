Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒÙŠ Ù…Ù† Ø§Ù„ØµÙØ± ÙŠÙØ¬Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ù†ØµÙˆØµ Ù…Ø«Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„Ø°ÙŠ Ø£ÙˆØ±Ø¯ØªÙÙ‡ØŒ ÙŠØ¬Ø¨ Ø£Ù† Ù†Ù…Ø±Ù‘ Ø¨Ø¹Ø¯Ø© Ù…Ø±Ø§Ø­Ù„ Ø£Ø³Ø§Ø³ÙŠØ© ØªØ¨Ø¯Ø£ Ù…Ù† **ØªØµÙ…ÙŠÙ… Ø§Ù„Ø¨Ù†ÙŠØ©** ÙˆØµÙˆÙ„Ù‹Ø§ Ø¥Ù„Ù‰ **ØªØ¯Ø±ÙŠØ¨ Ø°ÙƒÙŠ** ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ ØªÙ‚Ù†ÙŠØ§Øª Ø­Ø¯ÙŠØ«Ø© Ù…Ø«Ù„ **Low-Rank Adaptation (LoRA)**ØŒ **Quantization**ØŒ Ùˆ**Pipeline Parallelism**. Ø¥Ù„ÙŠÙƒ Ø®Ø·Ø© Ø´Ø§Ù…Ù„Ø© Ù…Ø¹ ÙƒÙˆØ¯ Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ®ØµÙŠØµ ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨:

---

### âœ… **1. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Base Model)**
Ø§Ø¨Ø¯Ø£ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ù„ØºÙˆÙŠ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± Ù…Ø«Ù„:

- **Qwen2-1.5B-Instruct**
- **Phi-3-mini-4k-instruct**
- **TinyLlama-1.1B**

Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ØµØºÙŠØ±Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ ÙˆÙŠÙ…ÙƒÙ† ØªØ¯Ø±ÙŠØ¨Ù‡Ø§ Ø¹Ù„Ù‰ Ø­Ø§Ø³ÙˆØ¨ Ø´Ø®ØµÙŠ Ø£Ùˆ GPU Ù…ØªÙˆØ³Ø·Ø©.

---

### âœ… **2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©**
```bash
pip install transformers datasets peft accelerate bitsandbytes trl torch
```

---

### âœ… **3. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**
Ù†ÙØªØ±Ø¶ Ø£Ù†Ùƒ ØªØ±ÙŠØ¯ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© **"Cosmos senior genius developer agent"**ØŒ Ø£ÙŠ Ø£Ù†Ù‡ Ø³ÙŠÙƒÙˆÙ† Ù…ØªØ®ØµØµÙ‹Ø§ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø£ÙƒÙˆØ§Ø¯ØŒ Ø­Ù„ÙˆÙ„ØŒ ÙˆØªØ­Ù„ÙŠÙ„Ø§Øª Ø°ÙƒÙŠØ©.

#### ğŸ“ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ dataset (JSONL):
```json
{"messages": [{"role": "system", "content": "You are a Cosmos senior genius developer agent!"}, {"role": "user", "content": "Write a Python function to reverse a linked list."}, {"role": "assistant", "content": "def reverse_linked_list(head):..."}]}
```

---

### âœ… **4. Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TRL + LoRA**
```python
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM
from trl import SFTTrainer
from peft import LoraConfig

model_id = "Qwen/Qwen2-1.5B-Instruct"
tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype="auto",
    device_map="auto"
)

tokenizer.chat_template = tokenizer.default_chat_template

dataset = load_dataset("json", data_files={"train": "train.jsonl", "test": "test.jsonl"})

def formatting_func(example):
    return tokenizer.apply_chat_template(example["messages"], tokenize=False)

peft_config = LoraConfig(
    r=32,
    lora_alpha=64,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

trainer = SFTTrainer(
    model=model,
    train_dataset=dataset["train"],
    eval_dataset=dataset["test"],
    formatting_func=formatting_func,
    peft_config=peft_config,
    tokenizer=tokenizer,
    args=dict(
        output_dir="./cosmos-agent",
        per_device_train_batch_size=2,
        gradient_accumulation_steps=4,
        num_train_epochs=2,
        fp16=True,
        save_steps=500,
        logging_steps=50,
        evaluation_strategy="steps",
        eval_steps=500,
        save_total_limit=2,
        load_best_model_at_end=True,
    )
)

trainer.train()
```

---

### âœ… **5. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨**
```python
from transformers import pipeline
import torch

finetuned_model = "./cosmos-agent"

pipeline = transformers.pipeline(
    "text-generation",
    model=finetuned_model,
    tokenizer=tokenizer,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)

messages = [
    {"role": "system", "content": "You are a Cosmos senior genius developer agent!"},
    {"role": "user", "content": "Write a Python function to calculate fibonacci numbers efficiently."},
]

outputs = pipeline(
    messages,
    max_new_tokens=256,
    do_sample=True,
    temperature=0.7
)

print(outputs[0]["generated_text"][-1]["content"])
```

---

### âœ… **6. Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø°ÙƒÙŠ**
- **Ø§Ø³ØªØ®Ø¯Ù… Data Augmentation**: ÙƒØ±Ø± Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨ØµÙŠØº Ù…Ø®ØªÙ„ÙØ©.
- **ØªØµÙÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**: Ø§Ø­Ø°Ù Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø£Ùˆ ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø©.
- **Ø§Ø³ØªØ®Ø¯Ù… Early Stopping** Ù„ØªØ¬Ù†Ø¨ Overfitting.
- **ÙƒÙ…Ù‘Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Quantize)** Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `bitsandbytes`.

---

### âœ… **7. Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ**
```python
trainer.save_model("cosmos-agent-final")
tokenizer.save_pretrained("cosmos-agent-final")
```

---

Ù‡Ù„ ØªØ±ØºØ¨ Ø£Ù† Ø£Ø¹Ø¯Ù‘ Ù„Ùƒ **dataset Ø¬Ø§Ù‡Ø²Ù‹Ø§** Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Cosmos Developer Agent)ØŸ
